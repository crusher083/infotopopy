{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nThis is my first example\n========================\n\nDescription of the example.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\nimport seaborn as sns\n\nimport timeit\n\nfrom infotopo import Infotopo\nfrom infotopo.io import load_data_sets\n\n\ndataset_type = 1 # if dataset = 1 load IRIS DATASET # if dataset = 2 load Boston house prices dataset # if dataset = 3 load DIABETES  dataset \n## if dataset = 4 CAUSAL Inference data challenge http://www.causality.inf.ethz.ch/data/LUCAS.html  # if dataset = 5 Borromean  dataset\n# if dataset = 6 Digits dataset MNIST\ndataset, nb_of_values = load_data_sets( dataset_type)\ndimension_max = dataset.shape[1]\ndimension_tot = dataset.shape[1]\nsample_size = dataset.shape[0]\nforward_computation_mode = False\nwork_on_transpose = False\nsupervised_mode = False\nsampling_mode = 1\ndeformed_probability_mode = False     \nif dataset_type == 6:\n    forward_computation_mode = True\n    dimension_max = 5\n\nprint(\"sample_size : \",sample_size)\nprint('number of variables or dimension of the analysis:',dimension_max )\nprint('number of tot  dimensions:',  dimension_tot)\nprint('number of values:', nb_of_values)\n\ninformation_topo = Infotopo(dimension_max = dimension_max, \n                            dimension_tot = dimension_tot, \n                            sample_size = sample_size, \n                            work_on_transpose = work_on_transpose,\n                            nb_of_values = nb_of_values, \n                            sampling_mode = sampling_mode, \n                            deformed_probability_mode = deformed_probability_mode,\n                            supervised_mode = supervised_mode, \n                            forward_computation_mode = forward_computation_mode)\n# Nentropy is dictionary (x,y) with x a list of kind (1,2,5) and y a value in bit    \nstart = timeit.default_timer()\nNentropie = information_topo.simplicial_entropies_decomposition(dataset) \nstop = timeit.default_timer()\nprint('Time for CPU(seconds) entropies: ', stop - start)\nif dataset_type == 1 or dataset_type == 5:\n    print(Nentropie)\ninformation_topo.entropy_simplicial_lanscape(Nentropie)\ninformation_topo = Infotopo(dimension_max = dimension_max, \n                            dimension_tot = dimension_tot, \n                            sample_size = sample_size, \n                            work_on_transpose = work_on_transpose,\n                            nb_of_values = nb_of_values, \n                            sampling_mode = sampling_mode, \n                            deformed_probability_mode = deformed_probability_mode,\n                            supervised_mode = supervised_mode, \n                            forward_computation_mode = forward_computation_mode,\n                            dim_to_rank = 3, number_of_max_val = 4)\nif dataset_type != 5:\n    dico_max, dico_min = information_topo.display_higher_lower_information(Nentropie, dataset)\n\n# Ninfomut is a dictionary (x,y) with x a list of kind (1,2,5) and y a value in bit\nNtotal_correlation = information_topo.total_correlation_simplicial_lanscape(Nentropie)\ndico_max, dico_min = information_topo.display_higher_lower_information(Ntotal_correlation, dataset)\nstart = timeit.default_timer()   \nNinfomut = information_topo.simplicial_infomut_decomposition(Nentropie)\nstop = timeit.default_timer()\nprint('Time for CPU(seconds) Mutual Information: ', stop - start)\nif dataset_type == 1 or dataset_type == 5:\n    print(Ninfomut)\ninformation_topo.mutual_info_simplicial_lanscape(Ninfomut)   \nif dataset_type != 5: \n    dico_max, dico_min = information_topo.display_higher_lower_information(Ninfomut, dataset)\nadjacency_matrix_mut_info = information_topo.mutual_info_pairwise_network(Ninfomut)\nmean_info, mean_info_rate  =information_topo.display_mean_information(Ninfomut)\n# CONDITIONAL INFO OR ENTROPY\nNcondInfo = information_topo.conditional_info_simplicial_lanscape(Ninfomut)\ninformation_topo.display_higher_lower_cond_information(NcondInfo)\n# ENTROPY vs. ENERGY LANDSCAPE\ninformation_topo.display_entropy_energy_landscape(Ntotal_correlation, Nentropie)\ninformation_topo.display_entropy_energy_landscape(Ninfomut, Nentropie)\n# Information distance and volume LANDSCAPE\nNinfo_volume = information_topo.information_volume_simplicial_lanscape(Nentropie, Ninfomut)\ndico_max, dico_min = information_topo.display_higher_lower_information(Ninfo_volume, dataset)\nadjacency_matrix_info_distance = information_topo.mutual_info_pairwise_network(Ninfo_volume)\n# Information paths - Information complex\nNinfomut, Nentropie =  information_topo.fit(dataset)\ninformation_topo.information_complex(Ninfomut)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}